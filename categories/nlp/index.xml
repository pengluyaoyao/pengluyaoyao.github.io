<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on Luyao Peng&#39;s Blog</title>
    <link>/categories/nlp/</link>
    <description>Recent content in NLP on Luyao Peng&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 25 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Gaussian Process in Deep and Wide Prediction Model in Automated Essay Scoring</title>
      <link>/post/gp-in-dw/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/gp-in-dw/</guid>
      <description>High stakes applications of NLP models such as educational assessments require a trade-off between the complex pattern recognition functionalities of deep learning models and the interpretability of knowledge-driven handcrafted features. In this paper, we propose a hybrid two-stage closed-form model called the Gaussian Process Deep and Wide Neu ral Networks (GPDWNNs) that combines strengths of knowledge-driven (wide) features with deep features from encoders such as BERT. Moreover, due to the closed-form solutions of GPDWNNs, we are able to significantly reduce computation time required for model parameter estimation versus training a deep network for comparable tasks.</description>
    </item>
    
    <item>
      <title>Project: NLP in Automated Essay Scoring</title>
      <link>/post/nlp-in-automated-essay-scoring/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/nlp-in-automated-essay-scoring/</guid>
      <description>In The Data Incubator, my capstone project was NLP in automated essay scoring, which was completed in Nov,2018, at that time, I havenâ€™t learned the techniques of NLP with deep learning, so this project only involves basic NLP methods such as BOW, n-gram and tree-based boosting model.
Link to the MMeM github
(The heroku platform only allows 30s response time for any request, sometimes the app takes takes more than 30s to respond due to an external API, please try multiple times to get the results.</description>
    </item>
    
    <item>
      <title>Project: Dependency Parsing Using Deep Learning NN Model</title>
      <link>/post/dependency-parsing/</link>
      <pubDate>Tue, 30 Aug 2011 16:01:23 +0800</pubDate>
      
      <guid>/post/dependency-parsing/</guid>
      <description>This project extends Neural Transition-based dependeny Parsing (Stanford U cs224n A#2 Q2). The goal is to build a three layer neural network using TensorFlow to parse the dependency structure of sentences. The orignal code contributed by hankcs is built in Python2. I revised it so it runs in Python3. The training data for the neural dependency parsing model is Penn Treebank, and each sentence has &amp;lsquo;word&amp;rsquo;, &amp;lsquo;POS&amp;rsquo;, &amp;lsquo;head&amp;rsquo; and &amp;lsquo;label&amp;rsquo;,</description>
    </item>
    
  </channel>
</rss>