<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on Luyao Peng&#39;s Blog</title>
    <link>/categories/nlp/</link>
    <description>Recent content in NLP on Luyao Peng&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 25 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Correspondence between Infinitely Wide Deep Neural Networks and a Gaussian Process</title>
      <link>/post/gp-in-dw/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/gp-in-dw/</guid>
      <description>Equivalency between Gaussian Process and DNNs Previous studies have shown the equivalency between Gaussian Process (GP) [1] and infinitely wide fully-connected Neural Networks (NNs) [2][4], which implies that if we choose a fully-connected NN with infinite width, the function computed by the NN is equivalent to a function drawn from a GP under appropriate statistical assumptions. The analytic forms of GP kernel for DNNs were also subsequentially developed.
The following figure shows the consistency between the theoretical GP (contour rings) and the sampled \(z_i\) at the initial layer (left) and the third layer (right) in a DNN.</description>
    </item>
    
    <item>
      <title>Project: NLP in Automated Essay Scoring</title>
      <link>/post/nlp-in-automated-essay-scoring/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/nlp-in-automated-essay-scoring/</guid>
      <description>In The Data Incubator, my capstone project was NLP in automated essay scoring, which was completed in Nov,2018, at that time, I havenâ€™t learned the techniques of NLP with deep learning, so this project only involves basic NLP methods such as BOW, n-gram and tree-based boosting model.
Link to the MMeM github
(The heroku platform only allows 30s response time for any request, sometimes the app takes takes more than 30s to respond due to an external API, please try multiple times to get the results.</description>
    </item>
    
    <item>
      <title>Project: Dependency Parsing Using Deep Learning NN Model</title>
      <link>/post/dependency-parsing/</link>
      <pubDate>Tue, 30 Aug 2011 16:01:23 +0800</pubDate>
      
      <guid>/post/dependency-parsing/</guid>
      <description>This project extends Neural Transition-based dependeny Parsing (Stanford U cs224n A#2 Q2). The goal is to build a three layer neural network using TensorFlow to parse the dependency structure of sentences. The orignal code contributed by hankcs is built in Python2. I revised it so it runs in Python3. The training data for the neural dependency parsing model is Penn Treebank, and each sentence has &amp;lsquo;word&amp;rsquo;, &amp;lsquo;POS&amp;rsquo;, &amp;lsquo;head&amp;rsquo; and &amp;lsquo;label&amp;rsquo;,</description>
    </item>
    
  </channel>
</rss>