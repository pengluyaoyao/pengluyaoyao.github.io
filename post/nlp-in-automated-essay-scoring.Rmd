---
title: NLP in Automated Essay Scoring
author: Luyao Peng
date: '2019-03-07'
slug: nlp-in-automated-essay-scoring
categories:
  - Python
  - My Projects
  - NLP
tags:
  - NLP
  - Python
---

In The Data Incubator, my capstone project was NLP in automated essay scoring, which was completed in Nov,2018, at that time, I haven't learned the techniques of NLP with deep learning, so this project only involves basic NLP methods such as BOW, n-gram and tree-based boosting model. 

[Link to the MMeM github](https://easygrader.herokuapp.com/)

(The heroku platform only allows 30s response time for any request, sometimes the app takes takes more than 30s to respond due to an external API, please try multiple times to get the results. This is what I need to improve to add some 'backend worker' in Python to avoid the situation)

1. About this project

Essay are crucial testing tools for assessing academic achievement, integration of ideas and ability, but are expensive and time consuming to grade manually. Automated Essay Scoring (AES) saves the efforts of human graders and hence significantly reduces costs and time.

The essay data are from Kaggle.com, by the William and Flora Hewlett Foundation, containing 8 essay categories. For each essay, there are two human graders to grade the essay. The goal is to train the models to grade the essays as close as to the human graders.

2. Features

This is traditional NLP method, so input features were extraced manually, they are: 
+ Bag of Words (BOW) 
+ Number of words 
+ Number of sentences 
+ Variation of sentences 
+ Average word length 
+ Number of lemms 
+ Number of spelling errors 
+ Number of nouns, adjectives, verbs and adverbs

3. Model and results

Four regression models are compared: + random forest + ridge regression + lasson regression + gradient boosting regressor
Gradient boosting regressor performed better in terms of Variance Explained metric, so gradi- ent boosting was used to make prediction on the validate essay set for set1 and set 5, respectively. 

After applying the early stopping, the results of gradient boosting regressor of the 3-fold cross
validation results for essay set1 and essay set5 are (the $R^2$ for other categories are 0.5-0.6, which is relatively low):

![](/post/2015-07-23-r-rmarkdown_files/figure-html/results_AES_TDI.jpg)

4. Problems

The model has overfitting problem, need to tune the parameters further; change the website waiting mode when requesting.

