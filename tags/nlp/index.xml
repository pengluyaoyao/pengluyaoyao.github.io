<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on Luyao Peng&#39;s Blog</title>
    <link>/tags/nlp/</link>
    <description>Recent content in NLP on Luyao Peng&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 06 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Window-based Name Entity Recognition</title>
      <link>/post/window_based_name_entity_recognition/</link>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/window_based_name_entity_recognition/</guid>
      <description>This assignment built 3 different models for named entity recognition (NER) task. For a given word in a context, we want to predict the name entity of the word in one of the following 5 categories:
 Person (PER): Organization (ORG): Location (LOC): Miscellaneous (MISC): Null (O): the word do not represent a named entity and most of the words fall into this categroy.  This is a 5-class classification problem, which implies a label vector of [PER, ORG, LOC, MISC, O].</description>
    </item>
    
    <item>
      <title>Project: NLP in Automated Essay Scoring</title>
      <link>/post/nlp-in-automated-essay-scoring/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/nlp-in-automated-essay-scoring/</guid>
      <description>In The Data Incubator, my capstone project was NLP in automated essay scoring, which was completed in Nov,2018, at that time, I havenâ€™t learned the techniques of NLP with deep learning, so this project only involves basic NLP methods such as BOW, n-gram and tree-based boosting model.
Link to the MMeM github
(The heroku platform only allows 30s response time for any request, sometimes the app takes takes more than 30s to respond due to an external API, please try multiple times to get the results.</description>
    </item>
    
    <item>
      <title>Project: Dependency Parsing Using Deep Learning NN Model</title>
      <link>/post/dependency-parsing/</link>
      <pubDate>Tue, 30 Aug 2011 16:01:23 +0800</pubDate>
      
      <guid>/post/dependency-parsing/</guid>
      <description>This project extends Neural Transition-based dependeny Parsing (Stanford U cs224n A#2 Q2). The goal is to build a three layer neural network using TensorFlow to parse the dependency structure of sentences. The orignal code contributed by hankcs is built in Python2. I revised it so it runs in Python3. The training data for the neural dependency parsing model is Penn Treebank, and each sentence has &amp;lsquo;word&amp;rsquo;, &amp;lsquo;POS&amp;rsquo;, &amp;lsquo;head&amp;rsquo; and &amp;lsquo;label&amp;rsquo;,</description>
    </item>
    
  </channel>
</rss>