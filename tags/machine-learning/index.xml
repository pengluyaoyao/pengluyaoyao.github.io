<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Luyao Peng&#39;s Blog</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Luyao Peng&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 05 Nov 2020 16:01:23 +0800</lastBuildDate>
    
	<atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sparse Variational Gaussian Process in Multiclass Classification</title>
      <link>/post/vgpc/</link>
      <pubDate>Thu, 05 Nov 2020 16:01:23 +0800</pubDate>
      
      <guid>/post/vgpc/</guid>
      <description>In this notebook, sparse variational gaussian process model (VGP) is applied to a multiclass classification problem. VGP is easily scalable to large scale dataset.
Background Consider making inference about a stochastic function \(f\) given a likelihood \(p(y|f)\) and \(N\) observations \(y=\{y_1, y_2, \dots, y_N\}^T\) at observation index points \(X=\{x_1, x_2, \dots, x_N\}^T\). Place a GP prior on \(f\): \(p(f) \sim N(f|m(X), K(X, X))\). The joint distribution of data and latent stochastic function is</description>
    </item>
    
    <item>
      <title>Machine Learning STAT209 Review</title>
      <link>/post/stat209/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/stat209/</guid>
      <description>--- title: &#39;Machine Learning STAT209 Review&#39; author: &#39;&#39; date: &#39;2019-03-11&#39; slug: STAT209 categories: - Statistics tags: - Machine Learning header-includes: \usepackage{amsmath} \usepackage{bm} --- 1. Bayes Classification Rule 1.1 Decision Rule Let \(\delta(\mathbf{x}) \rightarrow \left\{0, 1 \right\}\) be the classification rule for class 0 or 1. The expected cost is
\(R(\delta) = \int_{R_1(\mathbf{x})}\pi_0 Cost(1|0) f(\mathbf{x}|c = 0) + \int_{R_0(\mathbf{x})}\pi_1 Cost(0|1) f(\mathbf{x}|c = 1)\)
To minimize \(R(\delta)\), the decision rule is</description>
    </item>
    
  </channel>
</rss>